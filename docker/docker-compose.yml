# ==========================================================================
# NetTap Docker Compose — Unified Malcolm + NetTap stack
# ==========================================================================
# This is the single source of truth for all NetTap services.
# It uses Malcolm's published container images directly (Option C strategy)
# rather than depending on Malcolm's own docker-compose.
#
# Usage:
#   docker compose -f docker/docker-compose.yml up -d
#
# Prerequisites:
#   - Run scripts/install/deploy-malcolm.sh first to generate configs/certs
#   - Bridge (br0) must be configured before starting capture containers
#
# Security:
#   - Malcolm images must NOT have no-new-privileges or cap_drop: ALL — their
#     entrypoint (docker-uid-gid-setup.sh) uses `su` (setuid binary) for privilege
#     drop. no-new-privileges silently blocks setuid, cap_drop: ALL removes SETGID.
#   - NetTap custom services use no-new-privileges + cap_drop: ALL (we control entrypoints)
#   - Nginx-based containers need cap_add: CHOWN for cache dir ownership
#   - read_only filesystems where possible (with tmpfs for writable dirs)
#   - Internal services are not exposed to the host network
# ==========================================================================

x-malcolm-image: &malcolm-registry "ghcr.io/idaholab/malcolm"
x-malcolm-tag: &malcolm-tag "26.02.0"

x-process-env: &process-env
  PUID: ${PUID:-1000}
  PGID: ${PGID:-1000}

x-pcap-env: &pcap-env
  PCAP_IFACE: ${PCAP_IFACE:-br0}
  PCAP_IFACE_TWEAK: "true"

x-opensearch-env: &opensearch-env
  OPENSEARCH_URL: "https://opensearch:9200"
  OPENSEARCH_PRIMARY: "opensearch-local"
  OPENSEARCH_SSL_CERTIFICATE_VERIFICATION: "false"
  OPENSEARCH_COMPOSE_PROJECT: "nettap"
  OPENSEARCH_CREDS_CONFIG_FILE: "/var/local/curlrc/.opensearch.primary.curlrc"

x-capture-caps: &capture-caps
  - IPC_LOCK
  - SYS_RESOURCE
  - NET_ADMIN
  - NET_RAW
  - SYS_NICE

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 15s
  retries: 3

# -- Shared log rotation to prevent disk fill on 1TB SSD appliance -----------
# Malcolm uses driver: local with 200m/2 files. We match that to prevent
# verbose OpenSearch/Logstash logs from consuming the NVMe over months.
x-logging-defaults: &logging-defaults
  logging:
    driver: local
    options:
      max-size: "200m"
      max-file: "2"

# -- Security defaults for NetTap custom services only -------------------------
# Malcolm images must NOT use this — their entrypoint uses `su` (setuid binary)
# which silently fails with no-new-privileges, causing services to exit code 0.
x-security-defaults: &security-defaults
  security_opt:
    - no-new-privileges:true

services:

  # ========================================================================
  # DATA STORE
  # ========================================================================

  opensearch:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/opensearch:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-opensearch
    restart: unless-stopped
    <<: *logging-defaults
    # Protect OpenSearch from the Linux OOM killer. On 16GB target hardware
    # with 4g heap + Logstash + Zeek + Suricata, memory pressure is real.
    # Malcolm sets this to -500; we match that.
    oom_score_adj: -500
    labels:
      com.nettap.service: "opensearch"
      com.nettap.component: "data-store"
      com.nettap.description: "OpenSearch search and analytics engine"
    # NOTE: Do not use cap_drop: ALL on Malcolm images — their entrypoint chain
    # (docker-uid-gid-setup.sh → setup-internal-users.sh → self_signed_key_gen.sh)
    # needs standard capabilities for UID/GID setup and cert generation.
    cap_add:
      - IPC_LOCK           # required for memory locking
      - SYS_RESOURCE       # required for mlockall (bootstrap.memory_lock)
    environment:
      <<: [*process-env, *opensearch-env]
      OPENSEARCH_JAVA_OPTS: "${OPENSEARCH_JAVA_OPTS:--Xms4g -Xmx4g}"
      discovery.type: "single-node"
      bootstrap.memory_lock: "true"
      CLUSTER_MAX_SHARDS_PER_NODE: "2500"
      DISABLE_INSTALL_DEMO_CONFIG: "true"
      # Malcolm entrypoint configuration
      PUSER_RLIMIT_UNLOCK: "true"
      PUSER_CA_TRUST: "/var/local/ca-trust"
      MAX_LOCKED_MEMORY: "unlimited"
      cluster.routing.allocation.disk.threshold_enabled: "false"
      cluster.routing.allocation.node_initial_primaries_recoveries: "8"
      indices.query.bool.max_clause_count: "8192"
      path.repo: "/opt/opensearch/backup"
      logger.level: "WARN"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch-data:/usr/share/opensearch/data
      - opensearch-backup:/opt/opensearch/backup
      # Malcolm reads credentials from curlrc to set up internal users + security
      - ./curlrc:/var/local/curlrc:ro
      - ./ca-trust:/var/local/ca-trust:ro
    networks:
      - default
    healthcheck:
      <<: *healthcheck-defaults
      # Use Malcolm's built-in health script — it reads OPENSEARCH_CREDS_CONFIG_FILE,
      # adds --insecure explicitly, and checks the right endpoint.
      test: ["CMD", "/usr/local/bin/container_health.sh"]
      start_period: 180s

  # ========================================================================
  # DASHBOARDS
  # ========================================================================

  dashboards-helper:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/dashboards-helper:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-dashboards-helper
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "dashboards-helper"
      com.nettap.component: "dashboards"
      com.nettap.description: "OpenSearch Dashboards initialization helper"
    environment:
      <<: [*process-env, *opensearch-env]
      DASHBOARDS_URL: "http://dashboards:5601/dashboards"
      DASHBOARDS_DARKMODE: "true"
      DASHBOARDS_TIMEPICKER_FROM: "now-24h"
    volumes:
      - dashboards-helper-data:/opt/dashboards-helper
      - ./curlrc:/var/local/curlrc:ro
    networks:
      - default
    depends_on:
      opensearch:
        condition: service_healthy

  dashboards:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/dashboards:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-dashboards
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "dashboards"
      com.nettap.component: "dashboards"
      com.nettap.description: "OpenSearch Dashboards visualization UI"
    environment:
      <<: [*process-env, *opensearch-env]
    # NOTE: Dashboards does NOT need host-side cert mounts. It connects to
    # OpenSearch via HTTPS with OPENSEARCH_SSL_CERTIFICATE_VERIFICATION=false
    # and uses curlrc credentials. No TLS cert files are referenced.
    volumes:
      - ./curlrc:/var/local/curlrc:ro
    networks:
      - default
    depends_on:
      opensearch:
        condition: service_healthy

  # ========================================================================
  # LOG PIPELINE
  # ========================================================================

  logstash:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/logstash-oss:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-logstash
    restart: unless-stopped
    <<: *logging-defaults
    # NOTE: Logstash does NOT use *security-defaults (no-new-privileges).
    # Malcolm's entrypoint uses `su` (setuid) for privilege drop, but after su
    # the logstash user cannot reopen /proc/self/fd/1 (kernel procfs restriction:
    # l-wx------ root root). Supervisord's stdout_logfile=/dev/fd/1 fails EACCES.
    # Fix: PUSER_PRIV_DROP=false skips the su, supervisord runs as root (can open
    # /dev/fd/1), and our custom supervisord.conf adds user=logstash so the
    # logstash process itself runs as non-root.
    labels:
      com.nettap.service: "logstash"
      com.nettap.component: "log-pipeline"
      com.nettap.description: "Logstash log enrichment and forwarding pipeline"
    environment:
      <<: [*process-env, *opensearch-env]
      PUSER_PRIV_DROP: "false"
      LS_JAVA_OPTS: "${LS_JAVA_OPTS:--Xmx2g -Xms2g -Xss4m}"
      pipeline.workers: "${LOGSTASH_WORKERS:-2}"
      pipeline.batch.size: "125"
      LOGSTASH_OUI_LOOKUP: "true"
      LOGSTASH_SEVERITY_SCORING: "true"
      LOGSTASH_REVERSE_DNS: "false"
      BEATS_SSL: "false"
      LOGSTASH_HOST: "logstash:5044"
    # NOTE: No cert mount needed — BEATS_SSL is false, so logstash accepts
    # plaintext beats input. If BEATS_SSL is enabled in the future, mount
    # logstash-specific certs at /certs/ (ca.crt, server.crt, server.key).
    volumes:
      - logstash-persistent-queue:/usr/share/logstash/data/queue
      - ./curlrc:/var/local/curlrc:ro
      - ../config/logstash/supervisord.conf:/etc/supervisord.conf:ro
    networks:
      - default
    depends_on:
      opensearch:
        condition: service_healthy
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD-SHELL", "curl -sf http://localhost:9600/_node/pipelines || exit 1"]
      start_period: 600s

  filebeat:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/filebeat-oss:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-filebeat
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "filebeat"
      com.nettap.component: "log-pipeline"
      com.nettap.description: "Filebeat log shipper for Zeek and Suricata logs"
    environment:
      <<: [*process-env, *opensearch-env]
      FILEBEAT_SCAN_FREQUENCY: "10s"
      FILEBEAT_CLOSE_EOF: "true"
      FILEBEAT_CLEAN_INACTIVE: "180m"
      LOG_CLEANUP_MINUTES: "360"
      LOGSTASH_HOST: "logstash:5044"
      BEATS_SSL: "false"
    # NOTE: No cert mount needed — BEATS_SSL is false. If enabled in the future,
    # mount filebeat-specific certs at /certs/ (ca.crt, client.crt, client.key).
    volumes:
      - zeek-live-logs:/zeek/live:ro
      - suricata-live-logs:/var/log/suricata:ro
      - filebeat-registry:/usr/share/filebeat/data
      - ./curlrc:/var/local/curlrc:ro
    networks:
      - default
    depends_on:
      logstash:
        condition: service_healthy

  # ========================================================================
  # LIVE CAPTURE — These run with host networking for raw NIC access
  # ========================================================================
  # NOTE: Malcolm capture images must NOT have no-new-privileges or cap_drop: ALL.
  # Their entrypoint uses `su` (setuid binary) for privilege drop, which silently
  # fails with no-new-privileges. cap_add provides the capture capabilities needed.

  zeek-live:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/zeek:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-zeek-live
    restart: unless-stopped
    network_mode: host
    <<: *logging-defaults
    labels:
      com.nettap.service: "zeek-live"
      com.nettap.component: "capture"
      com.nettap.description: "Zeek network metadata analysis (live capture)"
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - SYS_NICE
    environment:
      <<: *process-env
      ZEEK_LIVE_CAPTURE: "true"
      PCAP_IFACE: "${PCAP_IFACE:-br0}"
      PCAP_IFACE_TWEAK: "true"
      ZEEK_LOG_PATH: "/zeek/live"
      ZEEK_EXTRACTOR_MODE: "none"
      ZEEK_LOCAL_NETS: "${ZEEK_LOCAL_NETS:-192.168.0.0/16,10.0.0.0/8,172.16.0.0/12}"
      ZEEK_ROTATED_PCAP: "false"
    volumes:
      - zeek-live-logs:/zeek/live
      - ../config/zeek/nettap.zeek:/opt/zeek/share/zeek/site/local.zeek:ro

  suricata-live:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/suricata:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-suricata-live
    restart: unless-stopped
    network_mode: host
    <<: *logging-defaults
    labels:
      com.nettap.service: "suricata-live"
      com.nettap.component: "capture"
      com.nettap.description: "Suricata IDS/IPS engine (live capture)"
    cap_add: *capture-caps
    environment:
      <<: *process-env
      SURICATA_LIVE_CAPTURE: "true"
      PCAP_IFACE: "${PCAP_IFACE:-br0}"
      PCAP_IFACE_TWEAK: "true"
      SURICATA_RUNMODE: "workers"
      SURICATA_UPDATE_RULES: "true"
      SURICATA_UPDATE_ETOPEN: "true"
      SURICATA_ROTATED_PCAP: "false"
    volumes:
      - suricata-live-logs:/var/log/suricata
      - suricata-rules:/var/lib/suricata/rules
      - ../config/suricata/nettap.yaml:/etc/suricata/nettap.yaml:ro

  pcap-capture:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/pcap-capture:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-pcap-capture
    restart: unless-stopped
    network_mode: host
    <<: *logging-defaults
    labels:
      com.nettap.service: "pcap-capture"
      com.nettap.component: "capture"
      com.nettap.description: "Raw packet capture (netsniff-ng)"
    cap_add: *capture-caps
    environment:
      <<: [*process-env, *pcap-env]
      PCAP_ENABLE_NETSNIFF: "true"
      PCAP_ROTATE_MEGABYTES: "${PCAP_ROTATE_MB:-4096}"
      PCAP_ROTATE_MINUTES: "${PCAP_ROTATE_MIN:-10}"
      PCAP_FILTER: ""
    volumes:
      - pcap-data:/pcap

  arkime-live:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/arkime:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-arkime-live
    restart: unless-stopped
    network_mode: host
    <<: *logging-defaults
    labels:
      com.nettap.service: "arkime-live"
      com.nettap.component: "capture"
      com.nettap.description: "Arkime full packet capture and session indexer"
    cap_add: *capture-caps
    environment:
      <<: [*process-env, *opensearch-env, *pcap-env]
      ARKIME_LIVE_CAPTURE: "true"
      ARKIME_VIEWER_PORT: "8005"
      ARKIME_ROTATE_INDEX: "daily"
      ARKIME_PACKET_THREADS: "${ARKIME_PACKET_THREADS:-2}"
      ARKIME_PASSWORD_SECRET: "${ARKIME_SECRET:-NetTap_Arkime_Secret}"
    # NOTE: Arkime self-generates viewer.crt/viewer.key inside the container
    # at startup via initarkime.sh. No host-side cert mount needed.
    volumes:
      - pcap-data:/data/pcap

  # ========================================================================
  # INFRASTRUCTURE
  # ========================================================================

  redis:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/redis:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-redis
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "redis"
      com.nettap.component: "infrastructure"
      com.nettap.description: "Redis in-memory data store for caching and queues"
    environment:
      <<: *process-env
      REDIS_PASSWORD: "${REDIS_PASSWORD:-NetTap_Redis_Secret}"
    volumes:
      - redis-data:/data
    networks:
      - default
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "redis-cli", "ping"]
      start_period: 30s

  api:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/api:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-api
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "api"
      com.nettap.component: "infrastructure"
      com.nettap.description: "Malcolm REST API server"
    environment:
      <<: [*process-env, *opensearch-env]
    # NOTE: API service does not need host-side certs. It connects to OpenSearch
    # via curlrc credentials with SSL verification disabled, and is accessed
    # through nginx-proxy (not directly over TLS).
    volumes:
      - ./curlrc:/var/local/curlrc:ro
    networks:
      - default
    depends_on:
      opensearch:
        condition: service_healthy

  nginx-proxy:
    image: "${MALCOLM_IMAGE_REGISTRY:-ghcr.io/idaholab/malcolm}/nginx-proxy:${MALCOLM_IMAGE_TAG:-26.02.0}"
    container_name: nettap-nginx-proxy
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "nginx-proxy"
      com.nettap.component: "infrastructure"
      com.nettap.description: "Malcolm nginx reverse proxy (internal dashboards)"
    ports:
      - "${MALCOLM_HTTPS_PORT:-9443}:443"
      # Bind OpenSearch proxy to loopback only — never expose 9200 externally
      - "127.0.0.1:9200:9200"
    environment:
      <<: [*process-env, *opensearch-env]
      NGINX_SSL: "true"
      NGINX_AUTH_MODE: "${NGINX_AUTH_MODE:-basic}"
      NGINX_LOG_ACCESS_AND_ERRORS: "false"
    volumes:
      - ${MALCOLM_CERTS_DIR:-./certs}:/etc/nginx/certs:ro
      - ${MALCOLM_AUTH_DIR:-./auth}:/etc/nginx/auth:ro
      - ./curlrc:/var/local/curlrc:ro
    networks:
      - default
    depends_on:
      - api
      - dashboards
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD-SHELL", "curl -skf https://localhost:443 || exit 1"]
      start_period: 120s

  # ========================================================================
  # NETTAP SERVICES
  # ========================================================================

  nettap-storage-daemon:
    build:
      context: ..
      dockerfile: docker/Dockerfile.daemon
    image: nettap/storage-daemon:latest
    container_name: nettap-storage-daemon
    restart: unless-stopped
    <<: [*security-defaults, *logging-defaults]
    labels:
      com.nettap.service: "storage-daemon"
      com.nettap.component: "nettap"
      com.nettap.description: "NetTap storage & health daemon — retention, SMART, disk management"
    cap_drop:
      - ALL
    read_only: true
    tmpfs:
      - /tmp:size=50M
    volumes:
      - ../config:/opt/nettap/config:ro
      - /dev:/dev:ro
      - storage-data:/var/lib/nettap
      - pcap-data:/opt/nettap/pcap:ro
    environment:
      <<: *opensearch-env
      RETENTION_HOT: "${RETENTION_HOT:-90}"
      RETENTION_WARM: "${RETENTION_WARM:-180}"
      RETENTION_COLD: "${RETENTION_COLD:-30}"
      DISK_THRESHOLD_PERCENT: "${DISK_THRESHOLD_PERCENT:-80}"
      PCAP_DIR: "/opt/nettap/pcap"
    # Daemon port is internal-only — only the web container needs it
    expose:
      - "8880"
    networks:
      - default
    depends_on:
      opensearch:
        condition: service_healthy

  nettap-web:
    build:
      context: ..
      dockerfile: docker/Dockerfile.web
    image: nettap/web:latest
    container_name: nettap-web
    restart: unless-stopped
    <<: [*security-defaults, *logging-defaults]
    labels:
      com.nettap.service: "web"
      com.nettap.component: "nettap"
      com.nettap.description: "NetTap web dashboard — SvelteKit network visibility UI"
    cap_drop:
      - ALL
    read_only: true
    tmpfs:
      - /tmp:size=50M
    # OLD CODE START — port was exposed directly before nginx reverse proxy
    # ports:
    #   - "${DASHBOARD_PORT:-443}:3000"
    # OLD CODE END — now nginx handles external TLS termination on 443
    expose:
      - "3000"
    volumes:
      - ../config:/opt/nettap/config:ro
      - web-data:/var/lib/nettap-web
    environment:
      <<: *opensearch-env
      NETTAP_HOSTNAME: "${NETTAP_HOSTNAME:-nettap.local}"
      DAEMON_URL: "http://nettap-storage-daemon:8880"
      CYBERCHEF_URL: "http://nettap-cyberchef:8443"
    networks:
      - default
    depends_on:
      opensearch:
        condition: service_healthy

  nettap-grafana:
    image: grafana/grafana:10.4.2
    container_name: nettap-grafana
    restart: unless-stopped
    <<: [*security-defaults, *logging-defaults]
    labels:
      com.nettap.service: "grafana"
      com.nettap.component: "nettap"
      com.nettap.description: "Grafana dashboards for enhanced network visualizations"
    cap_drop:
      - ALL
    environment:
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-nettap}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-opensearch-datasource
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
    volumes:
      - grafana-data:/var/lib/grafana
      - ../config/grafana/provisioning:/etc/grafana/provisioning:ro
      - ../config/grafana/dashboards:/var/lib/grafana/dashboards:ro
    expose:
      - "3000"
    networks:
      - default
    depends_on:
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  nettap-nginx:
    image: nginx:stable-alpine
    container_name: nettap-nginx
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "nginx"
      com.nettap.component: "nettap"
      com.nettap.description: "NetTap nginx reverse proxy — TLS termination, routing"
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    read_only: true
    tmpfs:
      - /var/cache/nginx:size=50M
      - /var/run:size=1M
      - /tmp:size=10M
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN            # nginx needs to chown cache directories
      - NET_BIND_SERVICE # nginx binds to ports 443 and 80
      - SETUID           # nginx master needs to switch to worker user
      - SETGID           # nginx master needs to set worker group
    networks:
      - default
    depends_on:
      - nettap-web
      - nettap-cyberchef
      - nettap-grafana
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD-SHELL", "wget -q --spider --no-check-certificate https://localhost:443/ || exit 1"]
      start_period: 15s

  nettap-tshark:
    build:
      context: ..
      dockerfile: docker/Dockerfile.tshark
    image: nettap/tshark:latest
    container_name: nettap-tshark
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "tshark"
      com.nettap.component: "nettap"
      com.nettap.description: "TShark packet decoder for on-demand PCAP analysis"
    read_only: true
    tmpfs:
      - /tmp:size=100M
    volumes:
      - pcap-data:/pcap:ro
    mem_limit: 512m
    cpus: 0.5
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    networks:
      - default

  nettap-cyberchef:
    build:
      context: ..
      dockerfile: docker/Dockerfile.cyberchef
    image: nettap/cyberchef:latest
    container_name: nettap-cyberchef
    restart: unless-stopped
    <<: *logging-defaults
    labels:
      com.nettap.service: "cyberchef"
      com.nettap.component: "nettap"
      com.nettap.description: "CyberChef data transformation and decoding tool"
    read_only: true
    tmpfs:
      - /tmp:size=10M
      - /var/cache/nginx:size=50M
      - /var/run:size=1M
    mem_limit: 128m
    cpus: 0.25
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN            # nginx needs to chown cache directories
      - SETUID           # nginx master needs to switch to worker user
      - SETGID           # nginx master needs to set worker group
    networks:
      - default
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD-SHELL", "wget -q --spider http://localhost:8443/health || exit 1"]
      start_period: 10s

# ==========================================================================
# VOLUMES
# ==========================================================================
volumes:
  # Malcolm data volumes
  opensearch-data:
  opensearch-backup:
  dashboards-helper-data:
  logstash-persistent-queue:
  filebeat-registry:
  redis-data:
  pcap-data:

  # Shared log volumes (written by capture, read by filebeat)
  zeek-live-logs:
  suricata-live-logs:
  suricata-rules:

  # NetTap data volumes
  storage-data:
  web-data:
  grafana-data:
